{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10d45218",
   "metadata": {},
   "source": [
    "# 🎗️ Breast Cancer Classification — ANN (Keras)\n",
    "A clean, reproducible notebook that trains an **Artificial Neural Network (ANN)** to classify **benign vs malignant** tumors on the **Breast Cancer Wisconsin (Diagnostic)** dataset.\n",
    "\n",
    "> This notebook mirrors the structure shown in your PDF and is ready to run inside your repo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037ec2f8",
   "metadata": {},
   "source": [
    "## 1) Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c06d635",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Core\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "\n",
    "# Deep Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Viz\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee50e7a",
   "metadata": {},
   "source": [
    "## 2) Load & Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29736be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = load_breast_cancer()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = pd.Series(data.target, name=\"target\")  # 0=malignant, 1=benign\n",
    "\n",
    "print(\"Shape:\", X.shape, y.shape)\n",
    "X.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9363ed",
   "metadata": {},
   "source": [
    "## 3) Train/Test Split & Scaling (no leakage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7ff598",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "X_train_scaled[:3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc7ed79",
   "metadata": {},
   "source": [
    "## 4) Build ANN (Keras Sequential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfb8880",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_dim = X_train_scaled.shape[1]\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(input_dim,)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    layers.Dropout(0.1),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476bbd9c",
   "metadata": {},
   "source": [
    "## 5) Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963d52af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=30,\n",
    "    batch_size=32,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Plot learning curves\n",
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "ax.plot(history.history['accuracy'], label='train acc')\n",
    "ax.plot(history.history['val_accuracy'], label='val acc')\n",
    "ax.set_xlabel('Epoch'); ax.set_ylabel('Accuracy'); ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "ax.legend(); plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "ax.plot(history.history['loss'], label='train loss')\n",
    "ax.plot(history.history['val_loss'], label='val loss')\n",
    "ax.set_xlabel('Epoch'); ax.set_ylabel('Loss'); ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "ax.legend(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5711864",
   "metadata": {},
   "source": [
    "## 6) Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a19764",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Accuracy\n",
    "y_pred_prob = model.predict(X_test_scaled).ravel()\n",
    "y_pred = (y_pred_prob >= 0.5).astype(int)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy:\", round(acc, 4))\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, target_names=data.target_names))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\\n\", cm)\n",
    "\n",
    "# ROC-AUC\n",
    "auc = roc_auc_score(y_test, y_pred_prob)\n",
    "print(\"\\nROC-AUC:\", round(auc, 4))\n",
    "\n",
    "# Plot ROC\n",
    "fpr, tpr, thr = roc_curve(y_test, y_pred_prob)\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.plot(fpr, tpr, label=f\"ROC-AUC={auc:.3f}\")\n",
    "plt.plot([0,1],[0,1],'--', linewidth=1)\n",
    "plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate'); plt.title('ROC Curve'); plt.legend(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b34ead6",
   "metadata": {},
   "source": [
    "## 7) Inference Helper (single sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f08570",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_single(sample: np.ndarray):\n",
    "    sample = sample.reshape(1, -1)\n",
    "    sample_scaled = scaler.transform(sample)\n",
    "    prob = float(model.predict(sample_scaled)[0][0])\n",
    "    return prob, int(prob >= 0.5)\n",
    "\n",
    "# Example with the first test row\n",
    "p, label = predict_single(X_test.iloc[0].values)\n",
    "print(\"Pred prob (benign):\", round(p, 4), \"→ Pred label:\", label, \"(0=malignant, 1=benign)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6701ee1e",
   "metadata": {},
   "source": [
    "## 8) Save Artifacts (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723ea4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save model and scaler if needed\n",
    "# model.save('models/ann_breast_cancer.h5')\n",
    "# import joblib; joblib.dump(scaler, 'models/scaler.joblib')\n",
    "print(\"Artifacts saving is commented out by default.\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}